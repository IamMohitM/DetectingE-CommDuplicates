{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code and Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import string\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(weights='imagenet', include_top=False)\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "image_feature = {}\n",
    "LSH_RESULTS = 'LSH File.txt'\n",
    "LSH_IMAGE_RESULTS= 'Lsh_Similar_images.txt'\n",
    "PROCESSED_GROUPS = 'Processed groups.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(text, n=3):\n",
    "    \"\"\"Return n-gram of a given text\"\"\"\n",
    "    n_grams = zip(*[text[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(img_url):\n",
    "    \"\"\"Downloads image of the given the url or returns\n",
    "    the features of the image if the image is already downloaded\n",
    "    Returns a black image in case of an exception\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        return image_feature[img_url]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            url_response = urllib.request.urlopen(img_url, timeout=30)\n",
    "            img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n",
    "            img = cv2.imdecode(img_array, -1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            img = np.dstack((img, img, img))\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            return img\n",
    "        except Exception:\n",
    "            return np.zeros((224, 224, 3))\n",
    "\n",
    "def extract_features(img_url, img):\n",
    "    \"\"\"Returns features of a given image using Visual Geometry Group 19 \"\"\"\n",
    "    try:\n",
    "        return image_feature[img_url]\n",
    "    except KeyError:\n",
    "        img_data = np.expand_dims(img, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "        feature = model.predict(img_data)\n",
    "        image_feature[img_url] = feature\n",
    "    return feature\n",
    "\n",
    "def compare_images(image_url, ids, other_urls):\n",
    "    \"\"\"Compares an image with a given set of images and return the ids that match a certain threshold\n",
    "    Input is the main image url, set of comparision ids and corresponding urls\n",
    "    \n",
    "    Uses download_image to download images and extract_features to extract image feature vectors\n",
    "    \"\"\"\n",
    "    image = download_image(image_url)\n",
    "    other_images = [(url, download_image(url)) for url in other_urls]\n",
    "    main_img = np.expand_dims(extract_features(image_url, image).flatten(), axis=0)\n",
    "    other_images = [extract_features(url, img).flatten() for url, img in other_images]\n",
    "    if not other_images:\n",
    "        return []\n",
    "    cosine_mat = cosine_similarity(main_img, other_images)\n",
    "    ids = np.array(ids)\n",
    "    return ids[np.argwhere(cosine_mat > 0.45)].flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lsh(group, col):\n",
    "    \"\"\"\n",
    "    Apply LSH to group of column and return the lsh object and a dictionary with key as the productId and minhash as the value\n",
    "    \"\"\"\n",
    "    lsh = MinHashLSH(threshold=0.9, num_perm=256)\n",
    "    minhashes = {}\n",
    "    for idx, text in group[col].iteritems():\n",
    "        minhash = MinHash(num_perm=256)\n",
    "        for d in ngrams(text, 3):\n",
    "            minhash.update(\"\".join(d).encode('utf-8'))\n",
    "        index = group.loc[idx, 'productId']\n",
    "        lsh.insert(key=index, minhash=minhash)\n",
    "        minhashes[index] = minhash\n",
    "    return lsh, minhashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(column):\n",
    "    \"Return frequency dictionary of all words in a column\"\n",
    "    word_list = []\n",
    "    for row in column:\n",
    "        word_list += word_tokenize(row)\n",
    "    return FreqDist(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_freq_words(text, frequent_words):\n",
    "    \"Remove words from the text using using the frequent words list\"\n",
    "    edited_text = ' '.join([word for word in text.split() if word.lower() not in frequent_words])\n",
    "    return edited_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_duplicates(group):\n",
    "    \"\"\"This function is applied to every group of productBrand and sub_category1 and compares the textual data and image data\n",
    "    to find duplicates\"\"\"\n",
    "    object_cols = ['key_specs_text', 'description', 'title']\n",
    "    similar_images = {}\n",
    "    duplicate_dict = {}\n",
    "\n",
    "    print(f'{group.name}: {group.shape}')\n",
    "\n",
    "    #Remove punctuation\n",
    "    for col in object_cols:\n",
    "        group[col] = group[col].fillna('').str.lower().str.translate(table)\n",
    "\n",
    "    #Concatenate Text\n",
    "    group['full_text'] = group['key_specs_text'].astype(str) + ' ' + group['description'].astype(str) + ' ' + group[\n",
    "        'title'].astype(str)\n",
    "    group['imageUrl'] = group['imageUrl'].fillna('')\n",
    "    \n",
    "    \n",
    "    word_freq = word_frequency(group['full_text'])\n",
    "    frequent_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    group['full_text'] = group['full_text'].apply(lambda text: remove_freq_words(text, frequent_words))\n",
    "    lsh, minhashes = apply_lsh(group, 'full_text')\n",
    "    \n",
    "    #For each productId and corresponding similar productIds as returned by LSH, compare the results\n",
    "    for key in minhashes.keys():\n",
    "        result = lsh.query(minhashes[key])\n",
    "        result = list(set([value for value in result if key != value]))\n",
    "        duplicate_dict[key] = result\n",
    "        if not result:\n",
    "            continue\n",
    "        key_url = group.loc[group['productId'] == key, 'imageUrl'].values[0]\n",
    "        result_url = group.loc[group['productId'].isin(result), 'imageUrl'].values.tolist()\n",
    "        similar_images[key] = list(set(compare_images(key_url, result, result_url)))\n",
    "\n",
    "    with open(LSH_IMAGE_RESULTS, 'a+') as f:\n",
    "        print(similar_images, file=f)\n",
    "    with open(LSH_RESULTS, 'a+') as f:\n",
    "        print(duplicate_dict, file=f)\n",
    "    with open(PROCESSED_GROUPS, 'a+') as p:\n",
    "        print(group.name, file=p)\n",
    "\n",
    "    \n",
    "    image_features = {}\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Final Data.csv')\n",
    "df = df.drop_duplicates(subset=['productId'])\n",
    "\n",
    "#Just a log file to check which groups have been processed to avoid re-preprocessing\n",
    "with open('Processed groups.txt', 'r') as f:\n",
    "    processed_groups = []\n",
    "    for line in f.readlines():\n",
    "        processed_groups.append(eval(line))\n",
    "try:\n",
    "    processed_brands, processed_cat1 = zip(*processed_groups)\n",
    "\n",
    "    df = df[~((df['productBrand'].isin(processed_brands)) &\n",
    "              (df['sub_category1'].isin(processed_cat1)))]\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "tqdm.pandas()\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "group_cols = ['productBrand', 'sub_category1']\n",
    "\n",
    "df = df.groupby(group_cols).filter(lambda group: len(group) > 1)\n",
    "grouped = df.groupby(group_cols)\n",
    "grouped.progress_apply(find_all_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compare to products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "import cv2, numpy as np, urllib, string, pandas as pd\n",
    "from keras.applications.vgg19 import preprocess_input, VGG19\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "model = VGG19(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### image\n",
    "def compare_products(product1, product2):\n",
    "    \"\"\"Checks if the two given series/dicts(strictly) belong to the same product\n",
    "    The keys should strictly be followed as per the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    product1 = product1.fillna('')\n",
    "    product2 = product2.fillna('')\n",
    "    if product1['imageUrl'] == product2['imageUrl']:\n",
    "        print('Yes')\n",
    "        return\n",
    "    text_cols = ['key_specs_text', 'description', 'title']\n",
    "    id1 = product1['productId']\n",
    "\n",
    "    check_image = False\n",
    "    product1['full_text'] = ''\n",
    "    product2['full_text'] = ''\n",
    "\n",
    "    for col in text_cols:\n",
    "        product1['full_text'] += ' ' + product1[col].translate(table)\n",
    "        product2['full_text'] += ' ' + product2[col].translate(table)\n",
    "\n",
    "    m1 = MinHash(num_perm=256)\n",
    "    m2 = MinHash(num_perm=256)\n",
    "\n",
    "    for d in ngrams(product1['full_text'], 3):\n",
    "        m1.update(d.encode('utf-8'))\n",
    "    for d in ngrams(product2['full_text'], 3):\n",
    "        m2.update(d.encode('utf-8'))\n",
    "\n",
    "    lsh = MinHashLSH(threshold=0.5, num_perm=256)\n",
    "    lsh.insert(id1, m1)\n",
    "    result = lsh.query(m2)\n",
    "    if id1 in result:\n",
    "        check_image = True\n",
    "    if not check_image:\n",
    "        print('No')\n",
    "    else:\n",
    "        print(product1['imageUrl'])\n",
    "        print(product2['imageUrl'])\n",
    "\n",
    "        img1 = download_image(product1['imageUrl'])\n",
    "        img2 = download_image(product2['imageUrl'])\n",
    "\n",
    "        img1 = np.expand_dims(extract_features(product1['imageUrl'], img1).flatten(), axis = 0)\n",
    "        img2 = np.expand_dims(extract_features(product2['imageUrl'], img2).flatten(), axis = 0)\n",
    "        print(img1.shape)\n",
    "        print(img2.shape)\n",
    "        cosine_mat = cosine_similarity(img1, img2)\n",
    "        if cosine_mat > 0.45:\n",
    "            print('Yes')\n",
    "        else:\n",
    "            print('No')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
